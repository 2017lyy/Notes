# 从计算机视觉的进步管窥AI发展

***

* 科学名家前沿进展系列讲座3
* 演讲：山世光
* 记录：王华强
* 2017.11.23

***

## 人工智能的发展历史

自第二次世界大战结束至今, 人工智能已经经历了三次潮起潮落. 二战后人们首先尝试使用符号推理来研究人工智能, 并以此衍生出了Lisp等语言. 在第二个阶段, 神经网络的出现为人们带来了新的希望. 不幸的是, 这个期望仍属过高. 此后, 人工知识+基于小数据的统计学习方法成为AI研究的主流. 其中, 多层的神经网络也是现在人工智能发展的基础之一. 近些年来, 由于处理器能力的不断发展, 多层神经网络为基础的深度学习取得了越来愈优秀的结果. 近些年来由于各大企业纷纷认识到AI的重要性, 导致人工智能领域近些年来风生水起. 可以说, 我们正在邂逅着一场AI发展的井喷.

## 人工智能的目标和进展

1997年, 深蓝在国际象棋上取得了对人类的最终胜利, 20年后, Deepmind在围棋上再下一城, 大大超过了专家所预期的3,40年的目标. 近些年来, 人工智能在机器翻译, 自动驾驶等等方向取得了很好的成果. 近期网络上的风格绘画转换算法, 也是人工智能的进展之一.

从风格绘画转换算法, 到微软小冰的诗集, 在这些情况中算法无法自己识别所生成的结果的优劣. 

## AI发展的背后 AI=A+B+C

行业内普遍认为, 近期AI的飞速发展, 离不开以下三个要素:

* A 算法: 深度学习
* B (Big data)大数据
* C 算力

以深度学习的复兴为例. 更具体地, 我们以深度学习中的计算机视觉为例, 探讨AI技术背后的内容. 

计算机视觉尝试去解读位图中蕴藏的, 人类可理解的内容. 

从人类神经网络的物理结构中, 计算机学家得到启发, 使用与之类似的加权投票模型来实现人工智能的功能. 神经系统在人的成长过程中经历了剪枝的的过程, 导致神经系统的链接决定了神经系统如何运作. 通过模仿神经系统, 使用剪枝等等方法建立连接网络, 人们得以训练一个深度学习模型.

最为经典的深度学习模型当属神经网络模型. 在上世纪40年代, 单神经元计算模型就已经开始出现. 这种模型利用卷积加权求和和非线性激活函数, 来判定"神经细胞"的活跃性. 一个很重要的问题是, 在建立一个单神经元计算模型时, 如何调整各个连接的权重? 同时, 一个神经元不需要与所有的其他神经元相连, 那么应该使用什么样的连接方式才相对合理?

解决方法就是所谓的多层神经网络. 从输入到输出, 中间设置多个隐含层. 在这样的网络中人们不知晓中间层的权重, 而学习过程就是调整这些权重的过程. 在计算机视觉中, 人们往往使用卷积神经网络, 其是目前在视觉和听觉处理上最优的算法.

卷积神经网络的历史可以追溯到上世纪80年代. 在其发展过程中从最初的三层, 层数逐渐增长, 直至千层. 与之相配的是对应的优化和训练方法的产生. 

深度神经网络参数的学习一直是这一技术的要点. 通过有标记的样本:"训练集", 应用BP算法来调整权重. 所谓BP算法, 是指通过对于梯度下降对权重的调整, 使得所有训练样本的总错误最小.

这一技术早在上世纪80年代就以在理论上证明可行, 然而, 在当时, 没有足够的样本集, 以及足够的计算能力. 但近些年来, 随着计算技术的不断发展, 互联网和大数据的兴起, 这一技术终于迎来了它的黄金时期.

## 现有AI的缺陷

```
    AI=Algorithm+Books+Calculate+Data+Environment
```

* 只有专科智能, 而且过度依赖于大数据.
* 是归纳法的结果.
* 急需研制可以掌握课本知识的AI.
* 机器知识与人类知识存在表示上的鸿沟.

一言以蔽之: 深度学习只解决了复杂相关性和非线性映射问题, 但是, 并没有解决因果的问题.

## 结语

在计算技术, 大数据飞速发展的当下, 人工智能的发展迎来了广阔的前景. 这一方向的研究方法也从由人类专家知识驱动的方法论转换到有监督的大数据驱动的研究. 但是, 现有AI仍然存在根本性的缺陷, 人工智能的研究仍然任重而道远.